{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hseoc\\Documents\\hse_lsml_final_project\\lsml_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "# Path to the saved model\n",
    "model_dir = \"../models/final_model\"\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_dir)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_dir)\n",
    "\n",
    "print(\"Model and tokenizer loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a sample input\n",
    "input_text = \"guess word: Это животное живет в Арктике и питается рыбой\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized input: {'input_ids': tensor([[    8, 10434,  9539,     8, 25486,    23,   129,  9754,  2845,     6,\n",
      "             8, 24165,    13,     5,  3904,   216,  2766,    60,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the input\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=64, truncation=True, padding=True)\n",
    "\n",
    "print(\"Tokenized input:\", inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-5 Predictions:\n",
      "1: пингвин\n",
      "2: лосось\n",
      "3: лемминго\n",
      "4: леммингов\n",
      "5: лемминг\n"
     ]
    }
   ],
   "source": [
    "# Generate prediction\n",
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    max_length=8,            # Limit output length\n",
    "    num_beams=5,             # Beam search with 5 beams\n",
    "    num_return_sequences=5,  # Return top-5 sequences\n",
    "    early_stopping=True      # Stop beams when all finish\n",
    ")\n",
    "\n",
    "# Decode all predictions\n",
    "predictions = [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]\n",
    "print(\"Top-5 Predictions:\")\n",
    "for i, pred in enumerate(predictions, 1):\n",
    "    print(f\"{i}: {pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: Это животное живет в лесу и ест мед\n",
      "Top-5 Predictions:; медовуха; медонос; медовник; пчела; медовик\n",
      "\n",
      "Input: Самая высокая гора на Земле\n",
      "Top-5 Predictions:; гора; вершина; саван; сопка; вулкан\n",
      "\n",
      "Input: Это транспортное средство, движущееся по рельсам\n",
      "Top-5 Predictions:; рельса; рельсоход; поезд; рельс; вагон\n",
      "\n",
      "Input: Это город, известный как столица Франции\n",
      "Top-5 Predictions:; Париж; город; франко; Франция; франк\n",
      "\n",
      "Input: Это орган, который перекачивает кровь по всему телу\n",
      "Top-5 Predictions:; сердечник; перекачка; лимфа; лимфоток; лимфатика\n",
      "\n",
      "Input: Самая длинная река в мире\n",
      "Top-5 Predictions:; река; Волга; речка; река; риф\n",
      "\n",
      "Input: Национальное блюдо Италии, сделанное из теста и сыра\n",
      "Top-5 Predictions:; пицца; итальянское блюдо; соус; итальянский пирог; блюдо\n",
      "\n",
      "Input: Это устройство, которое позволяет делать фотографии\n",
      "Top-5 Predictions:; фотоаппарат; фотограф; фотоаппарат; фотография; фотографа\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define multiple test inputs\n",
    "test_inputs = [\n",
    "    \"guess word: Это животное живет в лесу и ест мед\",\n",
    "    \"guess word: Самая высокая гора на Земле\",\n",
    "    \"guess word: Это транспортное средство, движущееся по рельсам\",\n",
    "    \"guess word: Это город, известный как столица Франции\",\n",
    "    \"guess word: Это орган, который перекачивает кровь по всему телу\",\n",
    "    \"guess word: Самая длинная река в мире\",\n",
    "    \"guess word: Национальное блюдо Италии, сделанное из теста и сыра\",\n",
    "    \"guess word: Это устройство, которое позволяет делать фотографии\"\n",
    "]\n",
    "\n",
    "# Iterate over test inputs\n",
    "for input_text in test_inputs:\n",
    "    # Tokenize input\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=64, truncation=True, padding=True)\n",
    "\n",
    "    # Generate top-5 outputs\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_length=8,\n",
    "        num_beams=5,\n",
    "        num_return_sequences=5,\n",
    "        early_stopping=True\n",
    "    )\n",
    "\n",
    "    # Decode predictions\n",
    "    predictions = [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]\n",
    "\n",
    "    # Print results\n",
    "    print(f'Input: {input_text.replace(\"guess word: \",\"\")}')\n",
    "    print(\"Top-5 Predictions:\", *predictions, sep=\"; \", end=\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lsml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
